{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kiran Rao\n",
    "\n",
    "d = dict()\n",
    "def clean(f):\n",
    "    #removes the punctuation marks \n",
    "    strg = \"\"\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~''' \n",
    "    for i in f:\n",
    "        #converted everything to lower case\n",
    "        i = i.lower()\n",
    "        for ele in i:\n",
    "            #replaced every punctuation mark with \"\"\n",
    "            if ele in punc:\n",
    "                i = i.replace(ele, \"\")\n",
    "        #created a string strg which contained the entire content of the file\n",
    "        strg = strg + str(i)\n",
    "    #split the string where \\n >= 2 which indicated that a new paragraph was coming in\n",
    "    par_list = strg.split('\\n\\n')\n",
    "    #created a new list which eliminated the empty elements of par_list\n",
    "    plist = []\n",
    "    for i in par_list:\n",
    "        if i!= '':\n",
    "            plist.append(i)\n",
    "    #filled the dictionary: key being the paragraph number and value being the content of the paragraph \n",
    "    j=0\n",
    "    dd = dict()\n",
    "    for line in plist:\n",
    "        dd[str(j)] = line\n",
    "        j +=1\n",
    "    #As \\n was giving some trouble, i split the value of the dictionary using \\n \n",
    "    #created a string appending each line of the paragraph which then was reassigned to the dictionary\n",
    "    for t in dd:\n",
    "        jh = dd[t].split(\"\\n\")\n",
    "        s = \"\"\n",
    "        for y in jh:\n",
    "            s = s+ y + \" \"\n",
    "            s = s.replace(\"  \", \" \") #removing the extra spaces in the middle of the paragraph\n",
    "        dd[str(t)] = s.strip() #removing the extra space from the end of the paragraph\n",
    "    \n",
    "    #deleting the dictionary elements with empty values\n",
    "    c = 0\n",
    "    for v in dd:\n",
    "        if(dd[v]) == '':\n",
    "            pass\n",
    "        else:\n",
    "            d[str(c)] = dd[v]\n",
    "            c = c+1\n",
    "        \n",
    "    #returning the dictionary\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_para_offset(ls, w):\n",
    "    off1 = dict()\n",
    "    for i in ls:\n",
    "        t = -1\n",
    "        li_o = [] # a list to store the offsets\n",
    "        #extract each word of the paragraph\n",
    "        for j in d[i].split(\" \"):\n",
    "            #increment the offset\n",
    "            t = t+1\n",
    "            #check if the query word is equal to the word at offset, if it is, add the offset to the list\n",
    "            if j == w:\n",
    "                li_o.append(t)\n",
    "        #assign the list as the value of the dictionary where the key is the paragraph number\n",
    "        off1[i] = li_o\n",
    "    return off1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_read_para(filename):\n",
    "    d_to_l = list(d.values()) #d_to_l is a list of paragraphs\n",
    "    para_stream = iter(d_to_l) #creating an iterator\n",
    "    try:\n",
    "        para = next(para_stream) #calling next to get the next paragraph\n",
    "        print(\"\\nContent of the next paragraph from the file specified in its input: \")\n",
    "        print(para.split(\" \")) #creating list of words of the paragraph\n",
    "    except StopIteration:\n",
    "        print(\"None\") #print none if end of file has reached\n",
    "    return para_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_in_para(para_stream, para_num):\n",
    "    d_to_l = list(d.values()) #list of paragraphs\n",
    "    print(\"\\nThe list of words in para \", para_num, \"in the order of appearance: \")\n",
    "    print(d_to_l[para_num].split(\" \")) #splitting by space to create a list of words in the paragraph specified\n",
    "    print(\"\\nThe paragraph by invoking next() on the iterator para_stream: \")\n",
    "    try:\n",
    "        para = next(para_stream) #calling next on the iterator para_stream\n",
    "        print(para)\n",
    "    except StopIteration:\n",
    "        print(\"None\") #print none if end of file has reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_in_all_paras(para_stream, para_num_list):\n",
    "    all_words = []\n",
    "    d_to_l = list(d.values()) #list of paragraphs\n",
    "    for i in para_num_list:\n",
    "        all_words.append(d_to_l[int(i)].split(\" \")) #creating a list of all words in all paragraphs given in the input list\n",
    "    print(all_words)\n",
    "    num = random.randrange(0, len(d_to_l)) #generating a random number which can be given as input to get_words_in_para\n",
    "    get_words_in_para(para_stream, num) #calling get_words_in_para using the random number generated\n",
    "#     get_words_in_para(para_stream, num)  #please feel free to uncomment these to test if none is being printed once end of file is reached \n",
    "#     get_words_in_para(para_stream, num)  #tested this on textfile2.txt to see if none is being printed\n",
    "#     get_words_in_para(para_stream, num)\n",
    "#     get_words_in_para(para_stream, num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives a dictionary where key is the words in the paragraphs specified\n",
    "#value is another dictionary where key is the paragraph in which the word appears\n",
    "#value is the offset values in that paragraph\n",
    "#although the words are from the paragraphs specified in the input list\n",
    "#the words are searched in the entire file to get the paragraph and offset values\n",
    "DICTIONARY = dict()\n",
    "def analyze_paras(para_stream, para_num_list):\n",
    "    #created a string containing all words from all paragraphs in the input list\n",
    "    str_of_words = \"\"\n",
    "    for i in para_num_list:\n",
    "        str_of_words = str_of_words + d[i] + \" \"\n",
    "        str_of_words.strip()\n",
    "        \n",
    "    l = []\n",
    "    l.append(str_of_words.split(\" \")) #used split on the space to create a list of all words\n",
    "    l = l[0] #l is a list of all words in all paras\n",
    "    \n",
    "    #tpn contains all the paragraph numbers in the file\n",
    "    tot_para_num = len(d)\n",
    "    tpn = []\n",
    "    for q in range(tot_para_num):\n",
    "        tpn.append(str(q))\n",
    "    \n",
    "    para_offset = dict()\n",
    "    for w in l: # word in list of all words\n",
    "        para_offset = get_para_offset(tpn, w) #called get_para_offset to get the dictionary containing para number and offset values\n",
    "        \n",
    "        #elimination of all the paragraphs that did not contain the word\n",
    "        dc = dict()\n",
    "        c = 0\n",
    "        for v in para_offset:\n",
    "            if(para_offset[v]) == []:\n",
    "                c +=1\n",
    "            else:\n",
    "                dc[str(c)] = para_offset[v]\n",
    "                c = c+1\n",
    "        \n",
    "        #appended the dictionary dc to the global dictionary DICTIONARY containing each word\n",
    "        DICTIONARY[w] = dc\n",
    "    print(DICTIONARY)\n",
    "    print(\"\\nAll words in all the paragraphs in the input list: \")\n",
    "    get_words_in_all_paras(para_stream, para_num_list) #called get_words_in_all_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(file_name, para_num_list):\n",
    "    para_stream = gen_read_para(file_name) #called gen_read_para to get the para_stream \n",
    "    print(\"\\nDictionary of words with paragraph numbers and corresponding offset values: \")\n",
    "    analyze_paras(para_stream, para_num_list) #called analyze_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# para2 = \"\"\n",
    "q_num = dict()\n",
    "para1 = []\n",
    "def main():\n",
    "    #user is prompted to enter the file name\n",
    "    file = input('Enter the file: ')\n",
    "    #possible file errors are handled\n",
    "    try:\n",
    "        fl = open(file, \"r\")\n",
    "    except FileNotFoundError as missing_file_err:\n",
    "        print(f'File is missing: {missing_file_err}')\n",
    "    else:\n",
    "        #clean function is called which returns the dictionary\n",
    "        clean(fl)\n",
    "        \n",
    "        #user is prompted to enter the paragraph numbers\n",
    "        para = input('Enter paragraph numbers: ')\n",
    "        pa = para.split(\" \")\n",
    "        \n",
    "        #handling the case where the user inputs an invalid paragraph number\n",
    "        for r in pa:\n",
    "            if int(r)>(len(d)-1):\n",
    "                print(\"Atleast one of the paragraph number entered is invalid\")\n",
    "                return\n",
    "            else:\n",
    "                pass\n",
    "                    \n",
    "            \n",
    "        #para is split to create a list containing the paragraph numbers\n",
    "        para1 = para.split(\" \")\n",
    "        \n",
    "        #while condition is used to enable endless sequence of queries until termination command is entered\n",
    "        while(True):\n",
    "            #user is prompted to enter either word or paragraph query\n",
    "            qry = input('\\nEnter your query: ')\n",
    "            #queries are asked until termination condition(/) is entered\n",
    "            if '/' in qry:\n",
    "                break\n",
    "            else:\n",
    "                #check if it starts with $ to identify word query\n",
    "                if(qry[0:2] == \"$ \"):\n",
    "                    #slicing is done to extarct only the word\n",
    "                    q = qry[2:]\n",
    "                    #dictionary is used to determine the number of times the query was called\n",
    "                    #every time the word query is enetered its respective count is increased\n",
    "                    q_num[q] = q_num.get(q,0)+1\n",
    "                    print(\"Number of times '\", q ,\"' has been queried: \", q_num[q])\n",
    "                            \n",
    "                    dc = get_para_offset(para1,q)\n",
    "\n",
    "                    #check if the queried word is present in any of the paragraphs or not\n",
    "                    ct = 0\n",
    "                    for z in dc:\n",
    "                        if dc[z] == []:\n",
    "                            ct = ct+1\n",
    "                            if(ct == len(para1)): #this means the queried word is not present in any of the paragraphs\n",
    "                                print(\"The word \", q, \"is not present in any of the paragraphs\")\n",
    "                        else:\n",
    "                            print(\"Para \", z, \": \", dc[z]) #paragraph number along with a list of offset is specified\n",
    "            \n",
    "                #check if it starts with # to identify paragraph query\n",
    "                elif(qry[0:2] == \"# \" and (int(qry[2:])>=0) and (int(qry[2:])<len(d))):\n",
    "                    a = 0\n",
    "                    #slicing is done to extract only the paragraph number\n",
    "                    p = qry[2]\n",
    "                    words_of_para = []\n",
    "                    #split the value of the dictionary to extract each word which is assigned to a list\n",
    "                    for i in d[p].split(\" \"):\n",
    "                        words_of_para.append(i)\n",
    "                    \n",
    "                    #random number is generated\n",
    "                    rnum = random.randrange(1, len(words_of_para))\n",
    "                    \n",
    "                    \n",
    "                    print(\"n -> \", len(words_of_para)) #total number of words in the specified paragraph\n",
    "                    print(\"1: \", words_of_para[0]) #first word in the paragraph\n",
    "                    print(\"n: \", words_of_para[-1]) #last word in the paragraph\n",
    "                    print(\"Random Num: \", rnum, \": \", words_of_para[rnum]) #random word in the paragraph where random number is generated\n",
    "                else:\n",
    "                    #Handling the invalid queries\n",
    "                    print(\"Invalid query\")\n",
    "                    \n",
    "        analyze(file, para1) #called analyze to initialize the process\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the file: textfile2.txt\n",
      "Enter paragraph numbers: 0\n",
      "\n",
      "Enter your query: $ and\n",
      "Number of times ' and ' has been queried:  1\n",
      "Para  0 :  [11, 37]\n",
      "\n",
      "Enter your query: # 3\n",
      "n ->  38\n",
      "1:  engineering\n",
      "n:  significance\n",
      "Random Num:  1 :  notation\n",
      "\n",
      "Enter your query: /\n",
      "\n",
      "Content of the next paragraph from the file specified in its input: \n",
      "['compared', 'to', 'normalized', 'scientific', 'notation', 'one', 'disadvantage', 'of', 'using', 'si', 'prefixes', 'and', 'engineering', 'notation', 'is', 'that', 'significant', 'figures', 'are', 'not', 'always', 'readily', 'apparent', 'when', 'the', 'smallest', 'significant', 'digit', 'or', 'digits', 'are', '0', 'for', 'example', '500', 'microns', 'micrometers', 'and', '500times106', 'meters', 'cannot', 'express', 'the', 'uncertainty', 'distinctions', 'between']\n",
      "\n",
      "Dictionary of words with paragraph numbers and corresponding offset values: \n",
      "{'compared': {'0': [0]}, 'to': {'0': [1], '1': [28, 59, 69]}, 'normalized': {'0': [2]}, 'scientific': {'0': [3], '3': [3]}, 'notation': {'0': [4, 13], '3': [1, 4]}, 'one': {'0': [5]}, 'disadvantage': {'0': [6]}, 'of': {'0': [7], '1': [15, 20], '2': [5, 13]}, 'using': {'0': [8], '2': [39]}, 'si': {'0': [9]}, 'prefixes': {'0': [10]}, 'and': {'0': [11, 37], '1': [4, 62], '2': [34]}, 'engineering': {'0': [12], '3': [0]}, 'is': {'0': [14], '1': [66], '2': [16, 26, 30, 46]}, 'that': {'0': [15], '2': [28], '3': [11]}, 'significant': {'0': [16, 26], '1': [63]}, 'figures': {'0': [17], '1': [64]}, 'are': {'0': [18, 30]}, 'not': {'0': [19], '2': [47], '3': [25]}, 'always': {'0': [20]}, 'readily': {'0': [21]}, 'apparent': {'0': [22]}, 'when': {'0': [23], '2': [2, 38]}, 'the': {'0': [24, 42], '1': [13, 16, 21, 24, 45, 71], '2': [3, 11, 14, 48], '3': [8, 20, 29]}, 'smallest': {'0': [25]}, 'digit': {'0': [27]}, 'or': {'0': [28], '1': [52], '2': [21, 42], '3': [18, 22]}, 'digits': {'0': [29]}, '0': {'0': [31]}, 'for': {'0': [32]}, 'example': {'0': [33], '1': [47], '2': [1]}, '500': {'0': [34]}, 'microns': {'0': [35]}, 'micrometers': {'0': [36]}, '500times106': {'0': [38]}, 'meters': {'0': [39], '1': [1, 3, 6]}, 'cannot': {'0': [40]}, 'express': {'0': [41]}, 'uncertainty': {'0': [43], '1': [61]}, 'distinctions': {'0': [44]}, 'between': {'0': [45], '2': [31]}, '': {}}\n",
      "\n",
      "All words in all the paragraphs in the input list: \n",
      "[['compared', 'to', 'normalized', 'scientific', 'notation', 'one', 'disadvantage', 'of', 'using', 'si', 'prefixes', 'and', 'engineering', 'notation', 'is', 'that', 'significant', 'figures', 'are', 'not', 'always', 'readily', 'apparent', 'when', 'the', 'smallest', 'significant', 'digit', 'or', 'digits', 'are', '0', 'for', 'example', '500', 'microns', 'micrometers', 'and', '500times106', 'meters', 'cannot', 'express', 'the', 'uncertainty', 'distinctions', 'between']]\n",
      "\n",
      "The list of words in para  3 in the order of appearance: \n",
      "['engineering', 'notation', 'like', 'scientific', 'notation', 'generally', 'can', 'use', 'the', 'enotation', 'such', 'that', '30times109', 'meterssec', 'can', 'be', 'written', '30e9', 'or', '30e9', 'the', 'e', 'or', 'e', 'should', 'not', 'be', 'confused', 'with', 'the', 'exponential', 'e', 'which', 'holds', 'a', 'completely', 'different', 'significance']\n",
      "\n",
      "The paragraph by invoking next() on the iterator para_stream: \n",
      "5times104 meters 50times104 meters and 500times104 meters this can be solved by changing the range of the coefficient in front of the power from the common 1 1000 to 0001 10 in some cases this may be suitable in others it may be impractical in the previous example 05 mm 050 mm or 0500 mm would have been used to show uncertainty and significant figures it is also common to state the precision explicitly such as 47 kilo ohms pm 5\n"
     ]
    }
   ],
   "source": [
    "#call of the main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
